data:
  train:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: torchvision.datasets
        class: CIFAR100
        CIFAR100:
          root: "'./dataset/cifar100'"
          train: True
          download: True
          transform: transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)), transforms.ToTensor(), transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])])
      batch_size: 64
      shuffle: True
      num_workers: 2

  valid:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: torchvision.datasets
        class: CIFAR100
        CIFAR100:
          root: "'./dataset/cifar100'"
          train: False
          download: True
          transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])])
      batch_size: 64
      shuffle: False
      num_workers: 2

model:
  module: models.mobilenets.mobilenetv3
  class: MobileNetV3Small
  MobileNetV3Small:
    num_classes: 100
    pretrained: True

loss:
  module: losses.loss
  class: Loss
  Loss:
    loss_fn:
      module: torch.nn
      class: CrossEntropyLoss
    output_transform: "lambda x: (x[0], x[1])"

optim:
  module: torch.optim
  class: Adam
  Adam:
    params: config['model'].parameters()
    lr: 0.001
    amsgrad: True

lr_scheduler:
  module: handlers.lr_scheduler
  class: ReduceLROnPlateau
  ReduceLROnPlateau:
    evaluator_name: "'valid'"
    score_name: "'loss'"
    optim: config['optim']
    mode: "'min'"
    factor: 0.1
    patience: 3
    verbose: True

early_stopping:
  module: handlers.early_stopping
  class: EarlyStopping
  EarlyStopping:
    evaluator_name: "'valid'"
    score_name: "'loss'"
    patience: 10
    delta: 0
    mode: "'min'"

metric:
  module: handlers.evaluator
  class: Metrics
  Metrics:
    metrics:
      accuracy:
        module: metrics.classification
        class: Metric
        Metric:
          metric_fn:
            module: metrics.classification
            class: Accuracy
            Accuracy:
              num_classes: 100
          output_transform: "lambda x: (x[0].softmax(dim=1), x[1])"
      loss:
        module: metrics.loss
        class: Loss
        Loss:
          loss_fn:
            module: torch.nn
            class: CrossEntropyLoss
          output_transform: "lambda x: (x[0], x[1])"

writer:
  module: handlers.writer
  class: Writer
  Writer:
    save_dir: "'checkpoint/CIFAR100/'"

plotter:
  module: handlers.plotter
  class: Plotter
  Plotter:
    save_dir: "'checkpoint/CIFAR100/'"

logger:
  module: handlers.logger
  class: Logger
  Logger:
    save_dir: "'checkpoint/CIFAR100/'"
    mode: logging.DEBUG
    format: "'%(asctime)s - %(name)s - %(levelname)s - %(message)s'"

model_inspection:
  module: handlers.inspect_model
  class: ModelInspection
  ModelInspection:
    verbose: True
    input_shape: "(32, 32, 1)"

trainer:
  module: engine
  class: Trainer
  Trainer:
    project_name: "'CIFAR100'"
    data:
      train: config['data']['train']
      train_eval: config['data']['train']
      valid: config['data']['valid']
      test: config['data']['valid']
    model: config['model']
    loss: config['loss']
    optim: config['optim']
    metric: config['metric']
    early_stopping: config['early_stopping']
    lr_scheduler: config['lr_scheduler']
    logger: config['logger']
    writer: config['writer']
    plotter: config['plotter']
    model_inspection: config['model_inspection']
    save_dir: "'checkpoint/CIFAR100/'"

extralibs:
  torch: torch
  logging: logging
  transforms: torchvision.transforms
