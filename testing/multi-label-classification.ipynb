{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-extreme",
   "metadata": {},
   "source": [
    "## Movie Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "every-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classes = list(dataframe.columns.drop(['Id', 'Genre']))\n",
    "labels = np.array(dataframe.drop(['Id', 'Genre'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hearing-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "image_paths = list(Path('./dataset/movie_poster/Images/').glob('**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "later-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7867"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "convinced-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('dataset/movie_poster/Images/tt0084058.jpg')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abandoned-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('./dataset/movie_poster/Images/')\n",
    "image_names = list(dataframe['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "challenging-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_path = str(image_dir.joinpath(image_names[0] + '.jpg'))\n",
    "image = cv2.imread(image_path)\n",
    "cv2.imshow('a', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "tight-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv('./dataset/movie_poster/origin/train.csv')\n",
    "\n",
    "image_dir = Path('./dataset/movie_poster/origin/Images/')\n",
    "image_extent = '.jpg'\n",
    "\n",
    "image_names = list(dataframe['Id'])\n",
    "image_paths = [str(image_dir.joinpath(image_name + image_extent)) for image_name in image_names]\n",
    "image_genres = list(dataframe['Genre'])\n",
    "labels = np.array(dataframe.drop(['Id', 'Genre'], axis=1))\n",
    "column_names = list(dataframe.columns)\n",
    "classes = list(dataframe.drop(['Id', 'Genre'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "immediate-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [[image_path, image_genre, label] for (image_path, image_genre, label) in zip(image_paths, image_genres, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "according-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.64\n",
    "valid_ratio = 0.16\n",
    "\n",
    "train_index = (0, int(round(len(items) * train_ratio)))\n",
    "valid_index = (int(round(len(items) * train_ratio)), int(round(len(items) * (train_ratio + valid_ratio))))\n",
    "test_index = (int(round(len(items) * (train_ratio + valid_ratio))), len(items))\n",
    "\n",
    "dirname = Path('./dataset/movie_poster/')\n",
    "\n",
    "train_dir = dirname.joinpath('train').joinpath('images')\n",
    "valid_dir = dirname.joinpath('valid').joinpath('images')\n",
    "test_dir = dirname.joinpath('test').joinpath('images')\n",
    "\n",
    "train_csv = dirname.joinpath('train').joinpath('train.csv')\n",
    "valid_csv = dirname.joinpath('valid').joinpath('valid.csv')\n",
    "test_csv = dirname.joinpath('test').joinpath('test.csv')\n",
    "\n",
    "for _dirname in [train_dir, valid_dir, test_dir]:\n",
    "    if not _dirname.exists():\n",
    "        _dirname.mkdir(parents=True)\n",
    "\n",
    "for data_index, _dirname, csv_path in zip([train_index, valid_index, test_index], [train_dir, valid_dir, test_dir], [train_csv, valid_csv, test_csv]):\n",
    "    info_data = {column_name: [] for column_name in column_names}\n",
    "    for (image_path, image_genre, label) in items[data_index[0]: data_index[1]]:\n",
    "        data_values = [Path(image_path).stem, image_genre]\n",
    "        data_values.extend(label)\n",
    "        for column_name, value in zip(info_data.keys(), data_values):\n",
    "            info_data[column_name].append(value)\n",
    "        shutil.copy(str(image_path), str(_dirname))\n",
    "    df = pd.DataFrame(info_data)\n",
    "    df.to_csv(str(csv_path), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-planet",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "based-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MovieGenreDataset(Dataset):\n",
    "    def __init__(self, datadir, csv_path, image_extent, image_size, inner_size, transforms=None):\n",
    "        super(MovieGenreDataset, self).__init__()\n",
    "        self.inner_size = inner_size\n",
    "        self.image_size = image_size\n",
    "        self.transforms = transforms if transforms is not None else []\n",
    "\n",
    "        df = pd.read_csv(str(csv_path))\n",
    "        image_paths = [str(Path(datadir).joinpath(image_name + image_extent)) for image_name in list(df['Id'])]\n",
    "        genres = list(df['Genre'])\n",
    "        labels = np.array(df.drop(['Id', 'Genre'], axis=1)).tolist()\n",
    "        self.classes = list(df.drop(['Id', 'Genre'], axis=1).columns)\n",
    "        self.data = [(image_path, genre, label) for image_path, genre, label in zip(image_paths, genres, labels)]\n",
    "        print(f'- {Path(datadir).parents[0].stem}: {len(self.data)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path, genre, label = self.data[idx]\n",
    "        sample = cv2.imread(str(image_path))\n",
    "        sample = self._resize(sample, self.inner_size)\n",
    "        \n",
    "        for transform in random.sample(self.transforms, k=random.randint(0, len(self.transforms))):\n",
    "            sample = transform(image=sample)\n",
    "\n",
    "        sample = cv2.resize(sample, dsize=self.image_size)\n",
    "        sample = np.ascontiguousarray(sample)\n",
    "        sample = torch.from_numpy(sample).permute(2, 0, 1).to(torch.float)\n",
    "\n",
    "        if (sample == sample.mean()).all():\n",
    "            sample = torch.zeros_like(sample)\n",
    "        else:\n",
    "            sample = (sample - sample.mean()) / sample.std()\n",
    "        \n",
    "        target = torch.from_numpy(np.asarray(label)).to(torch.float)\n",
    "\n",
    "        return sample, target, str(image_path)\n",
    "\n",
    "    def _resize(self, image, size):\n",
    "        ratio = size / min(image.shape[:2])\n",
    "        image = cv2.resize(image, dsize=(0, 0), fx=ratio, fy=ratio)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "resident-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train: 4643\n"
     ]
    }
   ],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "\n",
    "datadir = './dataset/movie_poster/train/images/'\n",
    "csv_path = './dataset/movie_poster/train/train.csv'\n",
    "image_extent = '.jpg'\n",
    "image_size = (400, 400)\n",
    "inner_size = 512\n",
    "transforms = [\n",
    "    iaa.Fliplr(p=0.5),\n",
    "    iaa.Flipud(p=0.5),\n",
    "]\n",
    "\n",
    "train_dataset = MovieGenreDataset(datadir, csv_path, image_extent, image_size, inner_size, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bacterial-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sized-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "samples, targets, image_paths = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "greenhouse-insulin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-assault",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "breeding-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained, features_fixed):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        self.model.features.requires_grad_(not features_fixed)\n",
    "        self.model.classifier[1] = torch.nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "alert-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(num_classes=25, pretrained=True, features_fixed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cultural-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor(size=(2, 3, 224, 224))\n",
    "output = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "southern-kernel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3779, -0.0399, -0.5283, -0.2736,  0.0342,  0.0615, -0.4062,  0.2205,\n",
       "          0.0389, -0.0725, -0.0208, -0.0050, -0.0278, -0.0926,  0.2643, -0.5408,\n",
       "         -0.1046, -0.2488,  0.0401,  0.1819, -0.4694,  0.1143, -0.2829, -0.1789,\n",
       "          0.0703],\n",
       "        [-0.1589, -0.0784, -0.6739, -0.4565,  0.1364,  0.1637, -0.1166, -0.0226,\n",
       "          0.1003, -0.4011,  0.2260,  0.1622,  0.9326, -0.0278, -0.3583, -0.5246,\n",
       "          0.0470, -0.2838,  0.4462,  0.2196, -0.5058,  0.0734, -0.1418, -0.4234,\n",
       "          0.0944]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ahead-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (output.sigmoid() > 0.6).to(torch.float)\n",
    "truth = torch.ones_like(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "antique-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4066, 0.4900, 0.3709, 0.4320, 0.5086, 0.5154, 0.3998, 0.5549, 0.5097,\n",
       "         0.4819, 0.4948, 0.4988, 0.4930, 0.4769, 0.5657, 0.3680, 0.4739, 0.4381,\n",
       "         0.5100, 0.5453, 0.3848, 0.5286, 0.4298, 0.4554, 0.5176],\n",
       "        [0.4604, 0.4804, 0.3376, 0.3878, 0.5341, 0.5408, 0.4709, 0.4943, 0.5251,\n",
       "         0.4011, 0.5563, 0.5405, 0.7176, 0.4931, 0.4114, 0.3718, 0.5118, 0.4295,\n",
       "         0.6097, 0.5547, 0.3762, 0.5183, 0.4646, 0.3957, 0.5236]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "applied-broadway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.sigmoid() >= torch.sort(output.sigmoid(), dim=1, des)[0][:,-3:-2]).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "turkish-motion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[0.3680, 0.3709, 0.3848, 0.3998, 0.4066, 0.4298, 0.4320, 0.4381, 0.4554,\n",
       "         0.4739, 0.4769, 0.4819, 0.4900, 0.4930, 0.4948, 0.4988, 0.5086, 0.5097,\n",
       "         0.5100, 0.5154, 0.5176, 0.5286, 0.5453, 0.5549, 0.5657],\n",
       "        [0.3376, 0.3718, 0.3762, 0.3878, 0.3957, 0.4011, 0.4114, 0.4295, 0.4604,\n",
       "         0.4646, 0.4709, 0.4804, 0.4931, 0.4943, 0.5118, 0.5183, 0.5236, 0.5251,\n",
       "         0.5341, 0.5405, 0.5408, 0.5547, 0.5563, 0.6097, 0.7176]],\n",
       "       grad_fn=<SortBackward>),\n",
       "indices=tensor([[15,  2, 20,  6,  0, 22,  3, 17, 23, 16, 13,  9,  1, 12, 10, 11,  4,  8,\n",
       "         18,  5, 24, 21, 19,  7, 14],\n",
       "        [ 2, 15, 20,  3, 23,  9, 14, 17,  0, 22,  6,  1, 13,  7, 16, 21, 24,  8,\n",
       "          4, 11,  5, 19, 10, 18, 12]]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(output.sigmoid(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "documentary-particular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5453],\n",
       "        [0.5563]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(output.sigmoid(), dim=1, descending=True)[0][..., 2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-library",
   "metadata": {},
   "source": [
    "## Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuous-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\"desert\": 0, \"mountains\": 1, \"sea\": 2, \"sunset\": 3, \"trees\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "double-mountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 2000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "\n",
    "image_paths = Path('../dataset/multi_labels/scenes/images/').glob('*.*')\n",
    "image_names = natsorted([image_path.stem for image_path in image_paths])\n",
    "print(f'number of images: {len(image_names)}')\n",
    "\n",
    "with open(file='../dataset/multi_labels/scenes/labels.json', mode='r') as fp:\n",
    "    lines = np.asarray([eval(line) for line in fp.readlines()])\n",
    "    lines[lines == -1] = 0\n",
    "\n",
    "for class_name, index in classes.items():\n",
    "    classes[class_name] = lines[:, index].tolist()\n",
    "\n",
    "csv_data = {**{'names': image_names}, **classes}\n",
    "df = pd.DataFrame(csv_data)\n",
    "df.to_csv('../dataset/multi_labels/scenes/train.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerical-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('../dataset/multi_labels/scenes/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-community",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>desert</th>\n",
       "      <th>mountains</th>\n",
       "      <th>sea</th>\n",
       "      <th>sunset</th>\n",
       "      <th>trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   names  desert  mountains  sea  sunset  trees\n",
       "0      1       1          0    0       0      0\n",
       "1      2       1          0    0       0      0\n",
       "2      3       1          0    0       0      0\n",
       "3      4       1          1    0       0      0\n",
       "4      5       1          0    0       0      0\n",
       "5      6       1          0    0       0      0\n",
       "6      7       1          1    0       0      0\n",
       "7      8       1          0    0       0      0\n",
       "8      9       1          0    0       0      0\n",
       "9     10       1          1    0       0      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secure-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv('../dataset/multi_labels/scenes/train.csv')\n",
    "\n",
    "image_dir = Path('../dataset/multi_labels/scenes/images/')\n",
    "image_extent = '.jpg'\n",
    "\n",
    "image_names = list(dataframe['names'])\n",
    "image_paths = [str(image_dir.joinpath(str(image_name) + image_extent)) for image_name in image_names]\n",
    "labels = np.array(dataframe.drop(['names'], axis=1))\n",
    "column_names = list(dataframe.columns)\n",
    "classes = list(dataframe.drop(['names'], axis=1).columns)\n",
    "\n",
    "items = [[image_path, label] for (image_path, label) in zip(image_paths, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improving-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(items)\n",
    "\n",
    "train_ratio = 0.64\n",
    "valid_ratio = 0.16\n",
    "\n",
    "train_index = (0, int(round(len(items) * train_ratio)))\n",
    "valid_index = (int(round(len(items) * train_ratio)), int(round(len(items) * (train_ratio + valid_ratio))))\n",
    "test_index = (int(round(len(items) * (train_ratio + valid_ratio))), len(items))\n",
    "\n",
    "dirname = Path('../dataset/multi_labels/scenes/')\n",
    "\n",
    "train_dir = dirname.joinpath('train').joinpath('images')\n",
    "valid_dir = dirname.joinpath('valid').joinpath('images')\n",
    "test_dir = dirname.joinpath('test').joinpath('images')\n",
    "\n",
    "train_csv = dirname.joinpath('train').joinpath('train.csv')\n",
    "valid_csv = dirname.joinpath('valid').joinpath('valid.csv')\n",
    "test_csv = dirname.joinpath('test').joinpath('test.csv')\n",
    "\n",
    "for _dirname in [train_dir, valid_dir, test_dir]:\n",
    "    if not _dirname.exists():\n",
    "        _dirname.mkdir(parents=True)\n",
    "\n",
    "for data_index, _dirname, csv_path in zip([train_index, valid_index, test_index], [train_dir, valid_dir, test_dir], [train_csv, valid_csv, test_csv]):\n",
    "    info_data = {column_name: [] for column_name in column_names}\n",
    "    for (image_path, label) in items[data_index[0]: data_index[1]]:\n",
    "        data_values = [Path(image_path).stem]\n",
    "        data_values.extend(label)\n",
    "        for column_name, value in zip(info_data.keys(), data_values):\n",
    "            info_data[column_name].append(value)\n",
    "        shutil.copy(str(image_path), str(_dirname))\n",
    "    df = pd.DataFrame(info_data)\n",
    "    df.to_csv(str(csv_path), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-outline",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "centered-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained, features_fixed):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.model = models.mobilenet_v2(pretrained=pretrained)\n",
    "        self.model.features.requires_grad_(not features_fixed)\n",
    "        self.model.classifier[1] = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "authorized-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "worth-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 1.8896e-40,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(size=(3, 224, 224))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "binding-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torchvision.transforms.ToPILImage()(a)\n",
    "a = torchvision.transforms.ToTensor()(a)\n",
    "a.shape\n",
    "# a = torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "suited-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = torch.from_numpy(np.array([1, 2, 3])).unsqueeze(dim=1).unsqueeze(dim=1).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pleased-recommendation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "separated-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "pad_to_square = iaa.PadToSquare(position='right-bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "breeding-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(2, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "supreme-teaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_to_square(image=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stable-partition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/phungpx/Downloads/dangkykinhdoanh_1095_060721')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = '/home/phungpx/Downloads/dangkykinhdoanh_1095_060721.txt'\n",
    "dirname = Path(file_path).parent.joinpath(Path(file_path).stem)\n",
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ab86c5-8404-4cdd-89c7-d1d6eb2c24a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('a/b/e.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolder = Path('a/b')\n",
    "file_url = 'c/d/e.f'\n",
    "subfolder.joinpath(Path(file_url).stem).with_suffix('.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "virgin-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='/home/phungpx/Downloads/dangkykinhdoanh_1095_060721.txt', mode='r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a098b1-2fa3-4510-a9d6-c9a594c5aed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e1ca90-8eb8-4daf-96f4-164bcbddfad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5afa896f-3bb9-4297-987f-6762e546b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = line.split('#')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52c58c5e-444c-4dd0-b8d1-82c42a1562c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8710264c-f362-4e5b-ab41-675eac2eb09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/image/tagging/GPKD/2021/03/công ty cổ phần/DAE1BA82-00DA-4017-BBB3-6898C5840F66.jpg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['imagePath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49e1212b-943c-4173-bcc8-7c6582096317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viet Nam Dat Nuoc Con Nguoi\n",
      "Welcome to Vietnam !\n",
      "VIET NAM DAT NUOC CON NGUOI\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def no_accent_vietnamese(s):\n",
    "    s = re.sub(r'[àáạảãâầấậẩẫăằắặẳẵ]', 'a', s)\n",
    "    s = re.sub(r'[ÀÁẠẢÃĂẰẮẶẲẴÂẦẤẬẨẪ]', 'A', s)\n",
    "    s = re.sub(r'[èéẹẻẽêềếệểễ]', 'e', s)\n",
    "    s = re.sub(r'[ÈÉẸẺẼÊỀẾỆỂỄ]', 'E', s)\n",
    "    s = re.sub(r'[òóọỏõôồốộổỗơờớợởỡ]', 'o', s)\n",
    "    s = re.sub(r'[ÒÓỌỎÕÔỒỐỘỔỖƠỜỚỢỞỠ]', 'O', s)\n",
    "    s = re.sub(r'[ìíịỉĩ]', 'i', s)\n",
    "    s = re.sub(r'[ÌÍỊỈĨ]', 'I', s)\n",
    "    s = re.sub(r'[ùúụủũưừứựửữ]', 'u', s)\n",
    "    s = re.sub(r'[ƯỪỨỰỬỮÙÚỤỦŨ]', 'U', s)\n",
    "    s = re.sub(r'[ỳýỵỷỹ]', 'y', s)\n",
    "    s = re.sub(r'[ỲÝỴỶỸ]', 'Y', s)\n",
    "    s = re.sub(r'[Đ]', 'D', s)\n",
    "    s = re.sub(r'[đ]', 'd', s)\n",
    "    s = re.sub(r'[-]', ' ', s)\n",
    "    return s\n",
    "\n",
    "print(no_accent_vietnamese(\"Việt Nam Đất Nước Con Người\"))\n",
    "print(no_accent_vietnamese(\"Welcome to Vietnam !\"))\n",
    "print(no_accent_vietnamese(\"VIỆT NAM ĐẤT NƯỚC CON NGƯỜI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23478e-3fcf-45c9-aaa4-e273e03dfcad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
